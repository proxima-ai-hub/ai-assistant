{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9353019,"sourceType":"datasetVersion","datasetId":5669721},{"sourceId":104453,"sourceType":"modelInstanceVersion","modelInstanceId":72256,"modelId":76277}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n\n%pip install -U peft\n%pip install -U trl\n%pip install -U bitsandbytes ","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:22:54.386357Z","iopub.execute_input":"2024-09-12T11:22:54.387198Z","iopub.status.idle":"2024-09-12T11:23:39.266788Z","shell.execute_reply.started":"2024-09-12T11:22:54.387164Z","shell.execute_reply":"2024-09-12T11:23:39.265657Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os, torch, wandb\n\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\n\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format\nfrom dataclasses import dataclass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup Huggingface 🤗 & Wandb","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"Proxima_hf\")\n\nlogin(token = hf_token)\n\nwb_token = user_secrets.get_secret(\"Proxima_wb\")\n\nwandb.login(key=wb_token)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:23:59.261704Z","iopub.execute_input":"2024-09-12T11:23:59.262288Z","iopub.status.idle":"2024-09-12T11:24:01.634613Z","shell.execute_reply.started":"2024-09-12T11:23:59.262261Z","shell.execute_reply":"2024-09-12T11:24:01.633674Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"@dataclass\nclass Config:\n#     model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n#     model_name = \"AnatoliiPotapov/T-lite-instruct-0.1\"\n    model_name = \"google/gemma-2-9b-it\"\n    dataset_name = \"/kaggle/input/proxima-data-qa\"\n#     new_model = \"llama-3.1-8b-proxima\"\n    new_model = \"gemma-2-9b-it-proxima\"\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"\ncfg = Config()","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:24:01.635655Z","iopub.execute_input":"2024-09-12T11:24:01.636253Z","iopub.status.idle":"2024-09-12T11:24:01.641757Z","shell.execute_reply.started":"2024-09-12T11:24:01.636227Z","shell.execute_reply":"2024-09-12T11:24:01.640836Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Loading model and tokenizer","metadata":{}},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=cfg.torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    cfg.model_name,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=cfg.attn_implementation\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:24:01.642751Z","iopub.execute_input":"2024-09-12T11:24:01.643024Z","iopub.status.idle":"2024-09-12T11:27:43.046465Z","shell.execute_reply.started":"2024-09-12T11:24:01.643001Z","shell.execute_reply":"2024-09-12T11:27:43.045439Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/857 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e024436d066a4319a3d90ffcd6d04a5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2da5462045d64640ad90b0e50544d7b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"793258bb4d7c4d3abbacb5c30a1ca543"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a45fcf58ef6c4c51aa7c242361610629"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3cfd0836dbe43a9a4d8cc35aba443e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28d865578d1e4546a49fe82208dec8fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c898f9f9c7e47b1882e1503ebce5936"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1001bb3a66b14801bb3070bd0be1444e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80c82d63936f4db7a303f91373179354"}},"metadata":{}}]},{"cell_type":"code","source":"# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\nmodel, tokenizer = setup_chat_format(model, tokenizer)\ntokenizer.padding_side = 'right'\ntokenizer.padding_token = '<|pad|>'","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:43.047675Z","iopub.execute_input":"2024-09-12T11:27:43.047990Z","iopub.status.idle":"2024-09-12T11:27:45.577942Z","shell.execute_reply.started":"2024-09-12T11:27:43.047956Z","shell.execute_reply":"2024-09-12T11:27:45.577107Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ce85d3aeb7f41a28a853af4c384925e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"042e1d5960f942599b72a3216b3d0307"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db9b73096fbe428bbd04c7b1ee1b32b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fda5de6fd96f4bc5970cdd4c43af8929"}},"metadata":{}}]},{"cell_type":"markdown","source":"## LoRA adapter","metadata":{}},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:45.579151Z","iopub.execute_input":"2024-09-12T11:27:45.579434Z","iopub.status.idle":"2024-09-12T11:27:46.731870Z","shell.execute_reply.started":"2024-09-12T11:27:45.579408Z","shell.execute_reply":"2024-09-12T11:27:46.730982Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(cfg.dataset_name, split=\"all\")","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:46.733059Z","iopub.execute_input":"2024-09-12T11:27:46.733363Z","iopub.status.idle":"2024-09-12T11:27:47.014889Z","shell.execute_reply.started":"2024-09-12T11:27:46.733339Z","shell.execute_reply":"2024-09-12T11:27:47.014197Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e107aab999c54452bcda47e44ed5db0f"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:47.019112Z","iopub.execute_input":"2024-09-12T11:27:47.019376Z","iopub.status.idle":"2024-09-12T11:27:47.025267Z","shell.execute_reply.started":"2024-09-12T11:27:47.019354Z","shell.execute_reply":"2024-09-12T11:27:47.024324Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Unnamed: 0', 'question', 'content', 'category', 'question_changed', 'content_changed', 'category_changed', 'catalog'],\n    num_rows: 1676\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Format to chat ","metadata":{}},{"cell_type":"code","source":"def format_chat_template(row):\n    row_json = [{\"role\": \"user\", \"content\": row[\"question_changed\"]},\n               {\"role\": \"assistant\", \"content\": row[\"content_changed\"]}]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:47.026771Z","iopub.execute_input":"2024-09-12T11:27:47.027223Z","iopub.status.idle":"2024-09-12T11:27:47.034737Z","shell.execute_reply.started":"2024-09-12T11:27:47.027187Z","shell.execute_reply":"2024-09-12T11:27:47.033824Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(\n    format_chat_template,\n    num_proc=4,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:47.035839Z","iopub.execute_input":"2024-09-12T11:27:47.036363Z","iopub.status.idle":"2024-09-12T11:27:48.333636Z","shell.execute_reply.started":"2024-09-12T11:27:47.036332Z","shell.execute_reply":"2024-09-12T11:27:48.332028Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1676 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"678447825c4b43e18f79f1cc50d08b8a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Select only part","metadata":{}},{"cell_type":"code","source":"dataset_sh = dataset.shuffle(seed=911).select(range(1676))","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:48.335727Z","iopub.execute_input":"2024-09-12T11:27:48.336447Z","iopub.status.idle":"2024-09-12T11:27:48.358735Z","shell.execute_reply.started":"2024-09-12T11:27:48.336397Z","shell.execute_reply":"2024-09-12T11:27:48.356979Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"dataset_sh","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:48.360292Z","iopub.execute_input":"2024-09-12T11:27:48.360665Z","iopub.status.idle":"2024-09-12T11:27:48.370563Z","shell.execute_reply.started":"2024-09-12T11:27:48.360627Z","shell.execute_reply":"2024-09-12T11:27:48.369444Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Unnamed: 0', 'question', 'content', 'category', 'question_changed', 'content_changed', 'category_changed', 'catalog', 'text'],\n    num_rows: 1676\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset_sh = dataset_sh.train_test_split(0.1)\ndataset_sh","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:48.371704Z","iopub.execute_input":"2024-09-12T11:27:48.372040Z","iopub.status.idle":"2024-09-12T11:27:48.396519Z","shell.execute_reply.started":"2024-09-12T11:27:48.372007Z","shell.execute_reply":"2024-09-12T11:27:48.395639Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Unnamed: 0', 'question', 'content', 'category', 'question_changed', 'content_changed', 'category_changed', 'catalog', 'text'],\n        num_rows: 1508\n    })\n    test: Dataset({\n        features: ['Unnamed: 0', 'question', 'content', 'category', 'question_changed', 'content_changed', 'category_changed', 'catalog', 'text'],\n        num_rows: 168\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=cfg.new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n#     num_train_epochs=1,\n    max_steps=500,\n    eval_strategy=\"steps\",\n    eval_steps=500,\n    logging_steps=100,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\",\n#     run_name=\"Llama-3.1-proxima\",\n    run_name=\"gemma-2-9b-it-proxima\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:48.397644Z","iopub.execute_input":"2024-09-12T11:27:48.397891Z","iopub.status.idle":"2024-09-12T11:27:48.433313Z","shell.execute_reply.started":"2024-09-12T11:27:48.397869Z","shell.execute_reply":"2024-09-12T11:27:48.432401Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"dataset_sh[\"train\"]['text'][0]","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:48.434341Z","iopub.execute_input":"2024-09-12T11:27:48.434596Z","iopub.status.idle":"2024-09-12T11:27:48.459410Z","shell.execute_reply.started":"2024-09-12T11:27:48.434575Z","shell.execute_reply":"2024-09-12T11:27:48.458486Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\nстатус уволен сотрудник в личный кабинет<|im_end|>\\n<|im_start|>assistant\\nпо данному вопросу вы можете обратиться в кадровую службу, создав заявку \"консультация по hr вопросам\"<|im_end|>\\n'"},"metadata":{}}]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset_sh[\"train\"],\n    eval_dataset=dataset_sh[\"test\"],\n    peft_config=peft_config,\n    max_seq_length=512,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:48.460677Z","iopub.execute_input":"2024-09-12T11:27:48.461063Z","iopub.status.idle":"2024-09-12T11:27:49.937850Z","shell.execute_reply.started":"2024-09-12T11:27:48.461031Z","shell.execute_reply":"2024-09-12T11:27:49.936981Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1508 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8762dca47ee54c58812b8d94bc79533a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/168 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"942cd276284b472e8eec232819f1d247"}},"metadata":{}},{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:49.939131Z","iopub.execute_input":"2024-09-12T11:27:49.939472Z","iopub.status.idle":"2024-09-12T11:43:14.297474Z","shell.execute_reply.started":"2024-09-12T11:27:49.939437Z","shell.execute_reply":"2024-09-12T11:43:14.296400Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms-v-savoskin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.18.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240912_112750-ljjzdlqi</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/s-v-savoskin/huggingface/runs/ljjzdlqi' target=\"_blank\">gemma-2-9b-it-proxima</a></strong> to <a href='https://wandb.ai/s-v-savoskin/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/s-v-savoskin/huggingface' target=\"_blank\">https://wandb.ai/s-v-savoskin/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/s-v-savoskin/huggingface/runs/ljjzdlqi' target=\"_blank\">https://wandb.ai/s-v-savoskin/huggingface/runs/ljjzdlqi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 15:02, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.657900</td>\n      <td>0.594068</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=500, training_loss=0.9965035552978516, metrics={'train_runtime': 923.4595, 'train_samples_per_second': 1.083, 'train_steps_per_second': 0.541, 'total_flos': 5018939197289472.0, 'train_loss': 0.9965035552978516, 'epoch': 0.6631299734748011})"},"metadata":{}}]},{"cell_type":"code","source":"path_to_save = \"Llama-finetuned\"\ntrainer.save_model(path_to_save)\nmodel.save_pretrained(path_to_save)\ntokenizer.save_pretrained(path_to_save)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:43:14.298860Z","iopub.execute_input":"2024-09-12T11:43:14.299244Z","iopub.status.idle":"2024-09-12T11:43:47.927535Z","shell.execute_reply.started":"2024-09-12T11:43:14.299209Z","shell.execute_reply":"2024-09-12T11:43:47.926432Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"('Llama-finetuned/tokenizer_config.json',\n 'Llama-finetuned/special_tokens_map.json',\n 'Llama-finetuned/tokenizer.model',\n 'Llama-finetuned/added_tokens.json',\n 'Llama-finetuned/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"# del model, tokenizer, trainer","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:43:47.929026Z","iopub.execute_input":"2024-09-12T11:43:47.929397Z","iopub.status.idle":"2024-09-12T11:43:47.934890Z","shell.execute_reply.started":"2024-09-12T11:43:47.929362Z","shell.execute_reply":"2024-09-12T11:43:47.933813Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Compare models","metadata":{}},{"cell_type":"markdown","source":"## Init casual LLM","metadata":{}},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=cfg.torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load model\ncasual_model = AutoModelForCausalLM.from_pretrained(\n    cfg.model_name,\n    quantization_config=bnb_config,\n#     device_map=\"auto\",\n    attn_implementation=cfg.attn_implementation\n)\n\ntokenizer = tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\ntokenizer.padding_side = 'right'\ntokenizer.padding_token = '<|pad_token|>'","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:43:47.936423Z","iopub.execute_input":"2024-09-12T11:43:47.936900Z","iopub.status.idle":"2024-09-12T11:45:07.513481Z","shell.execute_reply.started":"2024-09-12T11:43:47.936875Z","shell.execute_reply":"2024-09-12T11:45:07.512351Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfa2255f97cf494a8abd93cb07e36fd5"}},"metadata":{}}]},{"cell_type":"code","source":"casual_model, tokenizer = setup_chat_format(casual_model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:45:07.517017Z","iopub.execute_input":"2024-09-12T11:45:07.517352Z","iopub.status.idle":"2024-09-12T11:45:07.576257Z","shell.execute_reply.started":"2024-09-12T11:45:07.517323Z","shell.execute_reply":"2024-09-12T11:45:07.574922Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Get answers","metadata":{}},{"cell_type":"code","source":"def generate_answer(model, prompt):\n    chat = [\n        { \"role\": \"user\", \"content\": prompt },\n    ]\n    prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n    inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n    outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=150)\n\n    return(tokenizer.decode(outputs[0]))","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:45:07.578035Z","iopub.execute_input":"2024-09-12T11:45:07.580219Z","iopub.status.idle":"2024-09-12T11:45:07.588595Z","shell.execute_reply.started":"2024-09-12T11:45:07.580182Z","shell.execute_reply":"2024-09-12T11:45:07.587430Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Comprasion","metadata":{}},{"cell_type":"code","source":"q1 = \"как взять отгул\"\nq2 = \"не открываается моя карьера у сотрудника\"\nq3 = \"не приходит логин пароль\"","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:45:07.589791Z","iopub.execute_input":"2024-09-12T11:45:07.590176Z","iopub.status.idle":"2024-09-12T11:45:07.597739Z","shell.execute_reply.started":"2024-09-12T11:45:07.590143Z","shell.execute_reply":"2024-09-12T11:45:07.596513Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"generate_answer(model, q1)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:45:07.599094Z","iopub.execute_input":"2024-09-12T11:45:07.599409Z","iopub.status.idle":"2024-09-12T11:45:42.386409Z","shell.execute_reply.started":"2024-09-12T11:45:07.599383Z","shell.execute_reply":"2024-09-12T11:45:42.384941Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\nкак взять отгул<|im_end|>\\n<|im_start|>assistant\\nотгул можно взять, если отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник. отпуск по заявлению работник'"},"metadata":{}}]},{"cell_type":"code","source":"generate_answer(model, q2)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:45:42.387745Z","iopub.execute_input":"2024-09-12T11:45:42.388103Z","iopub.status.idle":"2024-09-12T11:46:16.412193Z","shell.execute_reply.started":"2024-09-12T11:45:42.388049Z","shell.execute_reply":"2024-09-12T11:46:16.411107Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\nне открываается моя карьера у сотрудника<|im_end|>\\n<|im_start|>assistant\\nсоздать заявку на сотрудника можно в разделе \"зар – заявки на сотрудни\". инструкция доступна по ссылке https://company-x5.ru/cms/z5/100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000'"},"metadata":{}}]},{"cell_type":"code","source":"generate_answer(model, q3)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:46:16.419301Z","iopub.execute_input":"2024-09-12T11:46:16.419717Z","iopub.status.idle":"2024-09-12T11:46:51.122801Z","shell.execute_reply.started":"2024-09-12T11:46:16.419679Z","shell.execute_reply":"2024-09-12T11:46:51.121711Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\nне приходит логин пароль<|im_end|>\\n<|im_start|>assistant\\nпри проблемах со входом в личный кабинет, прежде чем создавать заявку в поддержку, убедитесь, что заходите в личный кабинет на сайте https://company-x5.ru, указываете актуальные и верные логин и пароль. если вам неизвестен логин, обратитесь к руководителю (дм), он сможет посмотреть ваш логин и сбросить пароль в веб-табеле. для самостоятельного сброса пароля позвоните с вашего мобильного телефона на +7 (xxx) xxx xx xx, наберите добавочный номер 10100, нажмите * и подтвердите сброс пароля, нажав #. обновленный пароль отправьте по sms на +7 ('"},"metadata":{}}]},{"cell_type":"code","source":"print(generate_answer(casual_model, q1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_answer(casual_model, q2)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:47:12.601713Z","iopub.execute_input":"2024-09-12T11:47:12.602017Z","iopub.status.idle":"2024-09-12T11:47:34.445412Z","shell.execute_reply.started":"2024-09-12T11:47:12.601991Z","shell.execute_reply":"2024-09-12T11:47:34.444201Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\nне открываается моя карьера у сотрудника<|im_end|>\\n<|im_start|>assistant\\n<end_of_turn>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_answer(casual_model, 'hi')","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:47:34.446623Z","iopub.execute_input":"2024-09-12T11:47:34.447256Z","iopub.status.idle":"2024-09-12T11:47:55.858161Z","shell.execute_reply.started":"2024-09-12T11:47:34.447227Z","shell.execute_reply":"2024-09-12T11:47:55.856969Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\nhi<|im_end|>\\n<|im_start|>assistant\\n<end_of_turn><end_of_turn><eos><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><end_of_turn><eos><end_of_turn>.<end_of_turn><end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><end_of_turn>.'"},"metadata":{}}]}]}