{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9353019,"sourceType":"datasetVersion","datasetId":5669721},{"sourceId":104453,"sourceType":"modelInstanceVersion","modelInstanceId":72256,"modelId":76277}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n\n%pip install -U peft\n%pip install -U trl\n%pip install -U bitsandbytes ","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:22:54.386357Z","iopub.execute_input":"2024-09-12T11:22:54.387198Z","iopub.status.idle":"2024-09-12T11:23:39.266788Z","shell.execute_reply.started":"2024-09-12T11:22:54.387164Z","shell.execute_reply":"2024-09-12T11:23:39.265657Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os, torch, wandb\n\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    HfArgumentParser,\n    TrainingArguments,\n    pipeline,\n    logging,\n)\nfrom peft import (\n    LoraConfig,\n    PeftModel,\n    prepare_model_for_kbit_training,\n    get_peft_model,\n)\n\nfrom datasets import load_dataset\nfrom trl import SFTTrainer, setup_chat_format\nfrom dataclasses import dataclass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Setup Huggingface ü§ó & Wandb","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nhf_token = user_secrets.get_secret(\"Proxima_hf\")\n\nlogin(token = hf_token)\n\nwb_token = user_secrets.get_secret(\"Proxima_wb\")\n\nwandb.login(key=wb_token)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:23:59.261704Z","iopub.execute_input":"2024-09-12T11:23:59.262288Z","iopub.status.idle":"2024-09-12T11:24:01.634613Z","shell.execute_reply.started":"2024-09-12T11:23:59.262261Z","shell.execute_reply":"2024-09-12T11:24:01.633674Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: fineGrained).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"@dataclass\nclass Config:\n#     model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n#     model_name = \"AnatoliiPotapov/T-lite-instruct-0.1\"\n    model_name = \"google/gemma-2-9b-it\"\n    dataset_name = \"/kaggle/input/proxima-data-qa\"\n#     new_model = \"llama-3.1-8b-proxima\"\n    new_model = \"gemma-2-9b-it-proxima\"\n    torch_dtype = torch.float16\n    attn_implementation = \"eager\"\ncfg = Config()","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:24:01.635655Z","iopub.execute_input":"2024-09-12T11:24:01.636253Z","iopub.status.idle":"2024-09-12T11:24:01.641757Z","shell.execute_reply.started":"2024-09-12T11:24:01.636227Z","shell.execute_reply":"2024-09-12T11:24:01.640836Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Loading model and tokenizer","metadata":{}},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=cfg.torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load model\nmodel = AutoModelForCausalLM.from_pretrained(\n    cfg.model_name,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=cfg.attn_implementation\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:24:01.642751Z","iopub.execute_input":"2024-09-12T11:24:01.643024Z","iopub.status.idle":"2024-09-12T11:27:43.046465Z","shell.execute_reply.started":"2024-09-12T11:24:01.643001Z","shell.execute_reply":"2024-09-12T11:27:43.045439Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/857 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e024436d066a4319a3d90ffcd6d04a5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/39.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2da5462045d64640ad90b0e50544d7b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"793258bb4d7c4d3abbacb5c30a1ca543"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a45fcf58ef6c4c51aa7c242361610629"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3cfd0836dbe43a9a4d8cc35aba443e2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28d865578d1e4546a49fe82208dec8fe"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/3.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c898f9f9c7e47b1882e1503ebce5936"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1001bb3a66b14801bb3070bd0be1444e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/173 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80c82d63936f4db7a303f91373179354"}},"metadata":{}}]},{"cell_type":"code","source":"# Load tokenizer\ntokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\nmodel, tokenizer = setup_chat_format(model, tokenizer)\ntokenizer.padding_side = 'right'\ntokenizer.padding_token = '<|pad|>'","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:43.047675Z","iopub.execute_input":"2024-09-12T11:27:43.047990Z","iopub.status.idle":"2024-09-12T11:27:45.577942Z","shell.execute_reply.started":"2024-09-12T11:27:43.047956Z","shell.execute_reply":"2024-09-12T11:27:45.577107Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/47.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ce85d3aeb7f41a28a853af4c384925e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"042e1d5960f942599b72a3216b3d0307"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db9b73096fbe428bbd04c7b1ee1b32b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fda5de6fd96f4bc5970cdd4c43af8929"}},"metadata":{}}]},{"cell_type":"markdown","source":"## LoRA adapter","metadata":{}},{"cell_type":"code","source":"# LoRA config\npeft_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:45.579151Z","iopub.execute_input":"2024-09-12T11:27:45.579434Z","iopub.status.idle":"2024-09-12T11:27:46.731870Z","shell.execute_reply.started":"2024-09-12T11:27:45.579408Z","shell.execute_reply":"2024-09-12T11:27:46.730982Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(cfg.dataset_name, split=\"all\")","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:46.733059Z","iopub.execute_input":"2024-09-12T11:27:46.733363Z","iopub.status.idle":"2024-09-12T11:27:47.014889Z","shell.execute_reply.started":"2024-09-12T11:27:46.733339Z","shell.execute_reply":"2024-09-12T11:27:47.014197Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e107aab999c54452bcda47e44ed5db0f"}},"metadata":{}}]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:47.019112Z","iopub.execute_input":"2024-09-12T11:27:47.019376Z","iopub.status.idle":"2024-09-12T11:27:47.025267Z","shell.execute_reply.started":"2024-09-12T11:27:47.019354Z","shell.execute_reply":"2024-09-12T11:27:47.024324Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Unnamed: 0', 'question', 'content', 'category', 'question_changed', 'content_changed', 'category_changed', 'catalog'],\n    num_rows: 1676\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Format to chat ","metadata":{}},{"cell_type":"code","source":"def format_chat_template(row):\n    row_json = [{\"role\": \"user\", \"content\": row[\"question_changed\"]},\n               {\"role\": \"assistant\", \"content\": row[\"content_changed\"]}]\n    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n    return row","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:47.026771Z","iopub.execute_input":"2024-09-12T11:27:47.027223Z","iopub.status.idle":"2024-09-12T11:27:47.034737Z","shell.execute_reply.started":"2024-09-12T11:27:47.027187Z","shell.execute_reply":"2024-09-12T11:27:47.033824Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(\n    format_chat_template,\n    num_proc=4,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:47.035839Z","iopub.execute_input":"2024-09-12T11:27:47.036363Z","iopub.status.idle":"2024-09-12T11:27:48.333636Z","shell.execute_reply.started":"2024-09-12T11:27:47.036332Z","shell.execute_reply":"2024-09-12T11:27:48.332028Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/1676 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"678447825c4b43e18f79f1cc50d08b8a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Select only part","metadata":{}},{"cell_type":"code","source":"dataset_sh = dataset.shuffle(seed=911).select(range(1676))","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:48.335727Z","iopub.execute_input":"2024-09-12T11:27:48.336447Z","iopub.status.idle":"2024-09-12T11:27:48.358735Z","shell.execute_reply.started":"2024-09-12T11:27:48.336397Z","shell.execute_reply":"2024-09-12T11:27:48.356979Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"dataset_sh","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:48.360292Z","iopub.execute_input":"2024-09-12T11:27:48.360665Z","iopub.status.idle":"2024-09-12T11:27:48.370563Z","shell.execute_reply.started":"2024-09-12T11:27:48.360627Z","shell.execute_reply":"2024-09-12T11:27:48.369444Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['Unnamed: 0', 'question', 'content', 'category', 'question_changed', 'content_changed', 'category_changed', 'catalog', 'text'],\n    num_rows: 1676\n})"},"metadata":{}}]},{"cell_type":"code","source":"dataset_sh = dataset_sh.train_test_split(0.1)\ndataset_sh","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:48.371704Z","iopub.execute_input":"2024-09-12T11:27:48.372040Z","iopub.status.idle":"2024-09-12T11:27:48.396519Z","shell.execute_reply.started":"2024-09-12T11:27:48.372007Z","shell.execute_reply":"2024-09-12T11:27:48.395639Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['Unnamed: 0', 'question', 'content', 'category', 'question_changed', 'content_changed', 'category_changed', 'catalog', 'text'],\n        num_rows: 1508\n    })\n    test: Dataset({\n        features: ['Unnamed: 0', 'question', 'content', 'category', 'question_changed', 'content_changed', 'category_changed', 'catalog', 'text'],\n        num_rows: 168\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=cfg.new_model,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=4,\n    gradient_accumulation_steps=2,\n    optim=\"paged_adamw_32bit\",\n#     num_train_epochs=1,\n    max_steps=500,\n    eval_strategy=\"steps\",\n    eval_steps=500,\n    logging_steps=100,\n    warmup_steps=10,\n    logging_strategy=\"steps\",\n    learning_rate=2e-4,\n    fp16=False,\n    bf16=False,\n    group_by_length=True,\n    report_to=\"wandb\",\n#     run_name=\"Llama-3.1-proxima\",\n    run_name=\"gemma-2-9b-it-proxima\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:48.397644Z","iopub.execute_input":"2024-09-12T11:27:48.397891Z","iopub.status.idle":"2024-09-12T11:27:48.433313Z","shell.execute_reply.started":"2024-09-12T11:27:48.397869Z","shell.execute_reply":"2024-09-12T11:27:48.432401Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"dataset_sh[\"train\"]['text'][0]","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:48.434341Z","iopub.execute_input":"2024-09-12T11:27:48.434596Z","iopub.status.idle":"2024-09-12T11:27:48.459410Z","shell.execute_reply.started":"2024-09-12T11:27:48.434575Z","shell.execute_reply":"2024-09-12T11:27:48.458486Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\n—Å—Ç–∞—Ç—É—Å —É–≤–æ–ª–µ–Ω —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –≤ –ª–∏—á–Ω—ã–π –∫–∞–±–∏–Ω–µ—Ç<|im_end|>\\n<|im_start|>assistant\\n–ø–æ –¥–∞–Ω–Ω–æ–º—É –≤–æ–ø—Ä–æ—Å—É –≤—ã –º–æ–∂–µ—Ç–µ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ –∫–∞–¥—Ä–æ–≤—É—é —Å–ª—É–∂–±—É, —Å–æ–∑–¥–∞–≤ –∑–∞—è–≤–∫—É \"–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è –ø–æ hr –≤–æ–ø—Ä–æ—Å–∞–º\"<|im_end|>\\n'"},"metadata":{}}]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset_sh[\"train\"],\n    eval_dataset=dataset_sh[\"test\"],\n    peft_config=peft_config,\n    max_seq_length=512,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:48.460677Z","iopub.execute_input":"2024-09-12T11:27:48.461063Z","iopub.status.idle":"2024-09-12T11:27:49.937850Z","shell.execute_reply.started":"2024-09-12T11:27:48.461031Z","shell.execute_reply":"2024-09-12T11:27:49.936981Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n\nDeprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n  warnings.warn(message, FutureWarning)\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1508 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8762dca47ee54c58812b8d94bc79533a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/168 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"942cd276284b472e8eec232819f1d247"}},"metadata":{}},{"name":"stderr","text":"max_steps is given, it will override any value given in num_train_epochs\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:27:49.939131Z","iopub.execute_input":"2024-09-12T11:27:49.939472Z","iopub.status.idle":"2024-09-12T11:43:14.297474Z","shell.execute_reply.started":"2024-09-12T11:27:49.939437Z","shell.execute_reply":"2024-09-12T11:43:14.296400Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms-v-savoskin\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.18.0 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240912_112750-ljjzdlqi</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/s-v-savoskin/huggingface/runs/ljjzdlqi' target=\"_blank\">gemma-2-9b-it-proxima</a></strong> to <a href='https://wandb.ai/s-v-savoskin/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/s-v-savoskin/huggingface' target=\"_blank\">https://wandb.ai/s-v-savoskin/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/s-v-savoskin/huggingface/runs/ljjzdlqi' target=\"_blank\">https://wandb.ai/s-v-savoskin/huggingface/runs/ljjzdlqi</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [500/500 15:02, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.657900</td>\n      <td>0.594068</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=500, training_loss=0.9965035552978516, metrics={'train_runtime': 923.4595, 'train_samples_per_second': 1.083, 'train_steps_per_second': 0.541, 'total_flos': 5018939197289472.0, 'train_loss': 0.9965035552978516, 'epoch': 0.6631299734748011})"},"metadata":{}}]},{"cell_type":"code","source":"path_to_save = \"Llama-finetuned\"\ntrainer.save_model(path_to_save)\nmodel.save_pretrained(path_to_save)\ntokenizer.save_pretrained(path_to_save)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:43:14.298860Z","iopub.execute_input":"2024-09-12T11:43:14.299244Z","iopub.status.idle":"2024-09-12T11:43:47.927535Z","shell.execute_reply.started":"2024-09-12T11:43:14.299209Z","shell.execute_reply":"2024-09-12T11:43:47.926432Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:232: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"('Llama-finetuned/tokenizer_config.json',\n 'Llama-finetuned/special_tokens_map.json',\n 'Llama-finetuned/tokenizer.model',\n 'Llama-finetuned/added_tokens.json',\n 'Llama-finetuned/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"# del model, tokenizer, trainer","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:43:47.929026Z","iopub.execute_input":"2024-09-12T11:43:47.929397Z","iopub.status.idle":"2024-09-12T11:43:47.934890Z","shell.execute_reply.started":"2024-09-12T11:43:47.929362Z","shell.execute_reply":"2024-09-12T11:43:47.933813Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Compare models","metadata":{}},{"cell_type":"markdown","source":"## Init casual LLM","metadata":{}},{"cell_type":"code","source":"# QLoRA config\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=cfg.torch_dtype,\n    bnb_4bit_use_double_quant=True,\n)\n\n# Load model\ncasual_model = AutoModelForCausalLM.from_pretrained(\n    cfg.model_name,\n    quantization_config=bnb_config,\n#     device_map=\"auto\",\n    attn_implementation=cfg.attn_implementation\n)\n\ntokenizer = tokenizer = AutoTokenizer.from_pretrained(cfg.model_name)\ntokenizer.padding_side = 'right'\ntokenizer.padding_token = '<|pad_token|>'","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:43:47.936423Z","iopub.execute_input":"2024-09-12T11:43:47.936900Z","iopub.status.idle":"2024-09-12T11:45:07.513481Z","shell.execute_reply.started":"2024-09-12T11:43:47.936875Z","shell.execute_reply":"2024-09-12T11:45:07.512351Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"`low_cpu_mem_usage` was None, now set to True since model is quantized.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfa2255f97cf494a8abd93cb07e36fd5"}},"metadata":{}}]},{"cell_type":"code","source":"casual_model, tokenizer = setup_chat_format(casual_model, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:45:07.517017Z","iopub.execute_input":"2024-09-12T11:45:07.517352Z","iopub.status.idle":"2024-09-12T11:45:07.576257Z","shell.execute_reply.started":"2024-09-12T11:45:07.517323Z","shell.execute_reply":"2024-09-12T11:45:07.574922Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Get answers","metadata":{}},{"cell_type":"code","source":"def generate_answer(model, prompt):\n    chat = [\n        { \"role\": \"user\", \"content\": prompt },\n    ]\n    prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n    inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\n    outputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=150)\n\n    return(tokenizer.decode(outputs[0]))","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:45:07.578035Z","iopub.execute_input":"2024-09-12T11:45:07.580219Z","iopub.status.idle":"2024-09-12T11:45:07.588595Z","shell.execute_reply.started":"2024-09-12T11:45:07.580182Z","shell.execute_reply":"2024-09-12T11:45:07.587430Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Comprasion","metadata":{}},{"cell_type":"code","source":"q1 = \"–∫–∞–∫ –≤–∑—è—Ç—å –æ—Ç–≥—É–ª\"\nq2 = \"–Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–∞–µ—Ç—Å—è –º–æ—è –∫–∞—Ä—å–µ—Ä–∞ —É —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞\"\nq3 = \"–Ω–µ –ø—Ä–∏—Ö–æ–¥–∏—Ç –ª–æ–≥–∏–Ω –ø–∞—Ä–æ–ª—å\"","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:45:07.589791Z","iopub.execute_input":"2024-09-12T11:45:07.590176Z","iopub.status.idle":"2024-09-12T11:45:07.597739Z","shell.execute_reply.started":"2024-09-12T11:45:07.590143Z","shell.execute_reply":"2024-09-12T11:45:07.596513Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"generate_answer(model, q1)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:45:07.599094Z","iopub.execute_input":"2024-09-12T11:45:07.599409Z","iopub.status.idle":"2024-09-12T11:45:42.386409Z","shell.execute_reply.started":"2024-09-12T11:45:07.599383Z","shell.execute_reply":"2024-09-12T11:45:42.384941Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\n–∫–∞–∫ –≤–∑—è—Ç—å –æ—Ç–≥—É–ª<|im_end|>\\n<|im_start|>assistant\\n–æ—Ç–≥—É–ª –º–æ–∂–Ω–æ –≤–∑—è—Ç—å, –µ—Å–ª–∏ –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫. –æ—Ç–ø—É—Å–∫ –ø–æ –∑–∞—è–≤–ª–µ–Ω–∏—é —Ä–∞–±–æ—Ç–Ω–∏–∫'"},"metadata":{}}]},{"cell_type":"code","source":"generate_answer(model, q2)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:45:42.387745Z","iopub.execute_input":"2024-09-12T11:45:42.388103Z","iopub.status.idle":"2024-09-12T11:46:16.412193Z","shell.execute_reply.started":"2024-09-12T11:45:42.388049Z","shell.execute_reply":"2024-09-12T11:46:16.411107Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\n–Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–∞–µ—Ç—Å—è –º–æ—è –∫–∞—Ä—å–µ—Ä–∞ —É —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞<|im_end|>\\n<|im_start|>assistant\\n—Å–æ–∑–¥–∞—Ç—å –∑–∞—è–≤–∫—É –Ω–∞ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –º–æ–∂–Ω–æ –≤ —Ä–∞–∑–¥–µ–ª–µ \"–∑–∞—Ä ‚Äì –∑–∞—è–≤–∫–∏ –Ω–∞ —Å–æ—Ç—Ä—É–¥–Ω–∏\". –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞ –ø–æ —Å—Å—ã–ª–∫–µ https://company-x5.ru/cms/z5/100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000'"},"metadata":{}}]},{"cell_type":"code","source":"generate_answer(model, q3)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:46:16.419301Z","iopub.execute_input":"2024-09-12T11:46:16.419717Z","iopub.status.idle":"2024-09-12T11:46:51.122801Z","shell.execute_reply.started":"2024-09-12T11:46:16.419679Z","shell.execute_reply":"2024-09-12T11:46:51.121711Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\n–Ω–µ –ø—Ä–∏—Ö–æ–¥–∏—Ç –ª–æ–≥–∏–Ω –ø–∞—Ä–æ–ª—å<|im_end|>\\n<|im_start|>assistant\\n–ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö —Å–æ –≤—Ö–æ–¥–æ–º –≤ –ª–∏—á–Ω—ã–π –∫–∞–±–∏–Ω–µ—Ç, –ø—Ä–µ–∂–¥–µ —á–µ–º —Å–æ–∑–¥–∞–≤–∞—Ç—å –∑–∞—è–≤–∫—É –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É, —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∑–∞—Ö–æ–¥–∏—Ç–µ –≤ –ª–∏—á–Ω—ã–π –∫–∞–±–∏–Ω–µ—Ç –Ω–∞ —Å–∞–π—Ç–µ https://company-x5.ru, —É–∫–∞–∑—ã–≤–∞–µ—Ç–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –∏ –≤–µ—Ä–Ω—ã–µ –ª–æ–≥–∏–Ω –∏ –ø–∞—Ä–æ–ª—å. –µ—Å–ª–∏ –≤–∞–º –Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω –ª–æ–≥–∏–Ω, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—é (–¥–º), –æ–Ω —Å–º–æ–∂–µ—Ç –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤–∞—à –ª–æ–≥–∏–Ω –∏ —Å–±—Ä–æ—Å–∏—Ç—å –ø–∞—Ä–æ–ª—å –≤ –≤–µ–±-—Ç–∞–±–µ–ª–µ. –¥–ª—è —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ–≥–æ —Å–±—Ä–æ—Å–∞ –ø–∞—Ä–æ–ª—è –ø–æ–∑–≤–æ–Ω–∏—Ç–µ —Å –≤–∞—à–µ–≥–æ –º–æ–±–∏–ª—å–Ω–æ–≥–æ —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –Ω–∞ +7 (xxx) xxx xx xx, –Ω–∞–±–µ—Ä–∏—Ç–µ –¥–æ–±–∞–≤–æ—á–Ω—ã–π –Ω–æ–º–µ—Ä 10100, –Ω–∞–∂–º–∏—Ç–µ * –∏ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ —Å–±—Ä–æ—Å –ø–∞—Ä–æ–ª—è, –Ω–∞–∂–∞–≤ #. –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø–∞—Ä–æ–ª—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –ø–æ sms –Ω–∞ +7 ('"},"metadata":{}}]},{"cell_type":"code","source":"print(generate_answer(casual_model, q1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_answer(casual_model, q2)","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:47:12.601713Z","iopub.execute_input":"2024-09-12T11:47:12.602017Z","iopub.status.idle":"2024-09-12T11:47:34.445412Z","shell.execute_reply.started":"2024-09-12T11:47:12.601991Z","shell.execute_reply":"2024-09-12T11:47:34.444201Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\n–Ω–µ –æ—Ç–∫—Ä—ã–≤–∞–∞–µ—Ç—Å—è –º–æ—è –∫–∞—Ä—å–µ—Ä–∞ —É —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞<|im_end|>\\n<|im_start|>assistant\\n<end_of_turn>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generate_answer(casual_model, 'hi')","metadata":{"execution":{"iopub.status.busy":"2024-09-12T11:47:34.446623Z","iopub.execute_input":"2024-09-12T11:47:34.447256Z","iopub.status.idle":"2024-09-12T11:47:55.858161Z","shell.execute_reply.started":"2024-09-12T11:47:34.447227Z","shell.execute_reply":"2024-09-12T11:47:55.856969Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'<|im_start|>user\\nhi<|im_end|>\\n<|im_start|>assistant\\n<end_of_turn><end_of_turn><eos><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><end_of_turn><eos><end_of_turn>.<end_of_turn><end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><eos><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><end_of_turn>.<end_of_turn><end_of_turn>.'"},"metadata":{}}]}]}